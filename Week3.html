<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Week 3: Mixed-effect models</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr Nemanja Vaci" />
    <meta name="date" content="2022-09-03" />
    <script src="Week3_files/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Week 3: Mixed-effect models
]
.author[
### Dr Nemanja Vaci
]
.institute[
### University of Sheffield
]
.date[
### 09/03/2022
]

---






&lt;style type="text/css"&gt;
body, td {
   font-size: 15px;
}
code.r{
  font-size: 15px;
}
pre {
  font-size: 20px
}
.huge .remark-code { /*Change made here*/
  font-size: 200% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 80% !important;
}


&lt;/style&gt;

## Press record

---
## Intended aims

- Motivate usage of mixed-effect models, argument differences between types of pooling and explain how multilevel models differ from linear regression models

- Build a mixed-effect model in R environment with different random adjustments, estimate and interpret the coefficients

- Derive specific level estimate and evaluate the fit of the model

---
## Regression
__Gaussian distribution__:
`\(y_{i} \sim \mathcal{N^{iid}}(\mu_{i},\sigma)\)` &lt;br/&gt; &lt;br/&gt;
`\(\mu_{i} = \alpha+\beta*x_i\)` &lt;br/&gt;&lt;br/&gt; 
Model mean and standard deviation &lt;br/&gt; &lt;br/&gt; 
&lt;br/&gt;
&lt;br/&gt;
a) Errors: `\(\mathcal{N}^{iid}(0,\sigma)\)` &lt;br/&gt; &lt;br/&gt;
b) Linearity and additivity &lt;br/&gt; &lt;br/&gt;
c) Validity &lt;br/&gt; &lt;br/&gt;
d) Lack of perfect multicolinearity &lt;br/&gt; &lt;br/&gt;

???
We talked about what happens when the outcome is not following normal distributio and does not follow linearity assumption. This time around we will talk about IID assumptions and what to do in that case. 
---

## Correlated observations

__Nested structures__: observations nested hierarchically under general groups (eg. answers of pupils in the UK) &lt;br/&gt;  &lt;br/&gt;
 - Pupils are nested in ther classes &lt; schools &lt; counties &lt;br/&gt; &lt;br/&gt;
 
__Repeated measurements__: observations clustered within the participants &lt;br/&gt;  &lt;br/&gt;
- Participants answering on a number of questions in an experiment &lt;br/&gt; &lt;br/&gt;
- NBA players contributing multiple observations of their performance throughout their career &lt;br/&gt;&lt;br/&gt; 

__Clustering of the observations__ that are not nested: &lt;br/&gt; &lt;br/&gt;
- Questionnaire that collects profession of people and their country &lt;br/&gt; &lt;br/&gt;
---

## Multilevel models 

Generalization of regression `\((y_i=\alpha+\beta*x_i+\epsilon_i)\)`, where we allow adjustments of: &lt;br/&gt;&lt;br/&gt;
- __Intercept__: `\(y_i = \alpha_{j[i]}+\beta*x_i+\epsilon_i\)` &lt;br/&gt;&lt;br/&gt;
- __Slope__: `\(y_i=\alpha*\beta_{j[i]}*x_i+\epsilon_i\)` &lt;br/&gt;&lt;br/&gt;
- __Both__: `\(y_i=\alpha_{j[i]}*\beta_{j[i]}*x_i+\epsilon_i\)`&lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;
Visualisation of the idea: [Link](http://mfviz.com/hierarchical-models/)
---

## How to understand multilevel models

1. __Complete pooling__ - take into account all observations, without categorical information &lt;br/&gt;&lt;br/&gt;
2. __No pooling__ - adjust regression for each category  &lt;br/&gt; &lt;br/&gt;
3. __Partial pooling__ - use categories to adjust individual estimates &lt;br/&gt; &lt;br/&gt;




```r
knitr::kable(head(Babies), format = 'html')
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Babies_id &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; T_0s &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; T_1s &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Age &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Surounding &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Weight &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; CalorieIntake &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 27.47432 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -40.30564 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -5.375273 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 14.65666 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 665.2148 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 27.47432 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -40.30564 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 13 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.168467 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 12.91480 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 781.1619 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 27.47432 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -40.30564 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 43.613152 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.96138 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 850.2196 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 27.47432 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -40.30564 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 14.991462 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30.50425 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 777.9477 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 27.47432 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -40.30564 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 12.254607 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 29.12190 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 703.8290 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 27.47432 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -40.30564 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.587097 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 22.35996 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 741.4472 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
---
## Complete pooling

Linear model where we __ignore information__ about the countries: 


```r
mod1CP&lt;-lm(CalorieIntake~Age, data=Babies)
summary(mod1CP)
```

```
## 
## Call:
## lm(formula = CalorieIntake ~ Age, data = Babies)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1544.49  -226.93    79.93   295.13  1035.00 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  470.846     20.356   23.13   &lt;2e-16 ***
## Age           49.603      1.143   43.38   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 428.1 on 1998 degrees of freedom
## Multiple R-squared:  0.485,	Adjusted R-squared:  0.4848 
## F-statistic:  1882 on 1 and 1998 DF,  p-value: &lt; 2.2e-16
```

&lt;style type="text/css"&gt;
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 100px;
}
&lt;/style&gt;

&lt;style type="text/css"&gt;
.scroll-100 {
  max-height: 100px;
  overflow-y: auto;
  background-color: inherit;
}
&lt;/style&gt;
---

## Complete pooling

Looking at residuals:


```r
par(mfrow=c(1,1), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(resid(mod1CP), ylab='Residuals', xlab='Index')
```

&lt;img src="Week3_files/figure-html/unnamed-chunk-6-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---

## No pooling

Linear model where we estimates parameters for __each country__ separately:  


```r
mod1NP&lt;-lm(CalorieIntake~Age+factor(Babies_id)-1, data=Babies)
summary(mod1NP)
```

```
## 
## Call:
## lm(formula = CalorieIntake ~ Age + factor(Babies_id) - 1, data = Babies)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -809.29 -160.35   -6.41  162.10  855.07 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## Age                   50.2790     0.6783  74.124  &lt; 2e-16 ***
## factor(Babies_id)1   102.5872    20.9058   4.907 9.99e-07 ***
## factor(Babies_id)2   684.2652    20.6108  33.199  &lt; 2e-16 ***
## factor(Babies_id)3   862.3240    21.2219  40.634  &lt; 2e-16 ***
## factor(Babies_id)4  -305.3031    20.8831 -14.620  &lt; 2e-16 ***
## factor(Babies_id)5   487.4414    20.9251  23.295  &lt; 2e-16 ***
## factor(Babies_id)6   132.7962    21.0883   6.297 3.72e-10 ***
## factor(Babies_id)7   659.7740    20.8901  31.583  &lt; 2e-16 ***
## factor(Babies_id)8   656.3745    20.7328  31.659  &lt; 2e-16 ***
## factor(Babies_id)9   679.1863    20.4171  33.266  &lt; 2e-16 ***
## factor(Babies_id)10  642.8545    20.7242  31.019  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 253.2 on 1989 degrees of freedom
## Multiple R-squared:  0.9668,	Adjusted R-squared:  0.9666 
## F-statistic:  5259 on 11 and 1989 DF,  p-value: &lt; 2.2e-16
```

---

## No pooling


```r
par(mfrow=c(1,1), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(resid(mod1NP), ylab='Residuals',xlab='Index')
```

&lt;img src="Week3_files/figure-html/unnamed-chunk-8-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---

## Trade-off between the two approaches

_Complete pooling_ ignores variation between the categorical outcomes &lt;br/&gt; &lt;br/&gt;

_No pooling_ can overfit the data within each group, especially in the case when there are few observations per group or extreme cases &lt;br/&gt; &lt;br/&gt; &lt;br/&gt; &lt;br/&gt;

__Multilevel model (partial pooling)__&lt;br/&gt;

Multilevel estimates for a given country `\(j\)` can be approximated as a __weighted average__ of the mean of observations in the country (the unpooled estimate, `\(y_j\)`) and the mean over all countries (completely pooled estimate `\(y_{all}\)`) &lt;br/&gt; &lt;br/&gt;

---

## Shrinkage estimator 

Averages from countries with **.red[smaller sample size]** carry **.green[less information]**, and the weighting pulls multilevel estimates closer to the **.red[overall average]**. &lt;br/&gt;
If the `\(n_j=0\)` then overal average &lt;br/&gt;&lt;br/&gt;

Averages from countries with **.red[larger sample size]** carry **.green[more information]**, and the multilevel estimates are close to the country averages. &lt;br/&gt;
If `\(n_j-&gt;\infty\)` then country average &lt;br/&gt;&lt;br/&gt;

Every other time, multilevel estimates are between the two extremes &lt;br/&gt;

&lt;img src="Multi.png" width="40%" style="display: block; margin: auto;" /&gt;

---

## Multilevel model: intercept

`$$y_i \sim N(\alpha_{j[i]}+\beta*x_i, \sigma_y)$$` 
Estimation: `\(\alpha_j \sim N(\mu_\alpha, \sigma_\alpha)\)` &lt;br/&gt;
--

```r
#install.packages('lme4')
require(lme4)

mult1&lt;-lmer(CalorieIntake~Age+(1|Babies_id), data=Babies)
print(summary(mult1), cor=FALSE)
```

```
## Linear mixed model fit by REML ['lmerMod']
## Formula: CalorieIntake ~ Age + (1 | Babies_id)
##    Data: Babies
## 
## REML criterion at convergence: 27858.6
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.1994 -0.6327 -0.0245  0.6410  3.3694 
## 
## Random effects:
##  Groups    Name        Variance Std.Dev.
##  Babies_id (Intercept) 132275   363.7   
##  Residual               64118   253.2   
## Number of obs: 2000, groups:  Babies_id, 10
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 460.2558   115.6422    3.98
## Age          50.2773     0.6783   74.12
```

---

## Multilevel model: intercept and slope adjustments 

`$$y_i \sim N(\alpha_{j[i]}+\beta_{j[i]}*x_i, \sigma^2_y)$$` 

&lt;img src="insl.png" width="40%" style="display: block; margin: auto;" /&gt;
--

```r
mult2&lt;-lmer(CalorieIntake~Age+(1+Age|Babies_id), data=Babies)
print(summary(mult2), cor=FALSE)
```

```
## Linear mixed model fit by REML ['lmerMod']
## Formula: CalorieIntake ~ Age + (1 + Age | Babies_id)
##    Data: Babies
## 
## REML criterion at convergence: 25474.9
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.7037 -0.6672  0.0194  0.6576  4.0965 
## 
## Random effects:
##  Groups    Name        Variance Std.Dev. Corr 
##  Babies_id (Intercept) 35937.8  189.57        
##            Age           701.9   26.49   -0.50
##  Residual              18938.3  137.62        
## Number of obs: 2000, groups:  Babies_id, 10
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  469.579     60.307   7.786
## Age           50.048      8.386   5.968
```

---
## Comparison of residuals


```r
par(mfrow=c(1,3), bty='n',mar = c(5, 4,1, .1), cex=1.1, pch=16)
plot(resid(mod1CP)[1:200], ylab='Residuals',xlab='Index', main='Complete pooling', ylim=c(-1200,1200))
plot(resid(mod1NP)[1:200], ylab='Residuals',xlab='Index', main='No pooling', ylim=c(-1200,1200))
plot(resid(mult2)[1:200], ylab='Residuals',xlab='Index', main='Partial pooling', ylim=c(-1200,1200))
```

&lt;img src="Week3_files/figure-html/unnamed-chunk-13-1.png" width="100%" style="display: block; margin: auto;" /&gt;
---

## Fixed and random effects

Many different definitions: [LINK](https://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-and-mixed-effect-mode) &lt;br/&gt;


```r
fixef(mult2)
```

```
## (Intercept)         Age 
##   469.57946    50.04775
```


```r
ranef(mult2)
```

```
## $Babies_id
##    (Intercept)        Age
## 1    273.96266 -40.083989
## 2    -75.56727  19.518621
## 3     15.73010  22.659262
## 4   -130.81904 -40.356098
## 5    362.47248 -21.416831
## 6   -129.73763 -12.337377
## 7   -105.14316  18.855336
## 8     94.77461   6.176257
## 9   -209.91822  29.259636
## 10   -95.75452  17.725183
## 
## with conditional variances for "Babies_id"
```
---
## Intra-class correlation (ICC)

How strongly units withing the group correlate with each other

`\(\frac{\sigma^2_{\alpha}}{\sigma^2_{\alpha}+\sigma^2_y} = \frac{132275}{132275+64118}=0.673522\)`

&lt;br/&gt;&lt;br/&gt;

Works for only intercept random effect models


```r
mod1&lt;-lmer(CalorieIntake~Age+(1|Babies_id), data=Babies)
performance::icc(mod1)
```

```
## # Intraclass Correlation Coefficient
## 
##     Adjusted ICC: 0.674
##   Unadjusted ICC: 0.354
```

---

## Why multilevel modelling

1. Helps us with better inference about fixed effects &lt;br/&gt;
2. Interest in between group effects &lt;br/&gt;
3. Better inferences about levels of group not included in the sample &lt;br/&gt;
4. Deals better with the non-normality of outcomes &lt;br/&gt;
5. Deals better with outliers (shrinks them towards the mean)  &lt;br/&gt;
6. Deals better with unequal number of observations per group &lt;br/&gt;&lt;br/&gt;
&lt;br/&gt;&lt;br/&gt;

When is multilevel model equal to linear regression: &lt;br/&gt;

- Very little group-level variation - complete pooling &lt;br/&gt;

- Too much group-level variation - no pooling

???
How many groups/observations? - understanding partial pooling as a compromise between complete and no pooling indicates that the discussion about exact number of groups and observations is misguided. With few groups, we get classical regression - complete pooling and our multilevel model should be at least as good as linear regression. Having only two observations per group or even one observation in most of the groups might result in imprecise estimate of between group variance, but it should provide partial information that allows better estimation of parameters. 

---
class: inverse, middle, center
# Random effect structure 
---
## Specification of the structure

In all R packages, random effect structure can be specified using: &lt;br/&gt;&lt;br/&gt;

object &lt;- lmer(Dependent ~ Fixed (predictor) + __(1+|...)__, data=data) &lt;br/&gt;&lt;br/&gt;

- (1|Factor) = intercept adjustments for each level of factor &lt;br/&gt;&lt;br/&gt;
- (1+Predictor|Factor) = Intercept for each level of factor and slope adjustment for Predictor for each level of factor &lt;br/&gt;&lt;br/&gt;
- (0 + Predictor|Factor) or (Predictor - 1|Factor) = Slope adjustment for Predictor for each level of factor &lt;br/&gt;&lt;br/&gt;


???
LMERs cheat sheet: &lt;br/&gt;&lt;br/&gt; 
- [LINK 1](https://stats.stackexchange.com/a/13173) &lt;br/&gt;&lt;br/&gt;
- [LINK 2](https://stats.stackexchange.com/a/61466)

---

## Nested effects

&lt;img src="nested.png" width="80%" style="display: block; margin: auto;" /&gt;
 &lt;br/&gt;&lt;br/&gt;
 
Random effect specification: (1|Country/Region) &lt;br/&gt;&lt;br/&gt;
Responses are nested within regions, that are further nested within Countries &lt;br/&gt;&lt;br/&gt; 

---

## Crossed random effects

&lt;img src="crossed2.png" width="40%" style="display: block; margin: auto;" /&gt;

Random effect specification: (1|Country) + (1|Region) &lt;br/&gt;
Responses have multimembership status, they are nested in a combination of countries  &lt;br/&gt; 

In the experimental situations (psycholinguistics): this will be the case. Responses in experimental paradigm are nested in two random structures simultaneously: participants and stimuli 

---

## How to decide what to include

There are no recipes, except that you need to think about your model and what it does &lt;br/&gt;

There is some advice from the experts and it is that we should keep it maximal! [LINK](https://talklab.psy.gla.ac.uk/KeepItMaximalR2.pdf) &lt;br/&gt; &lt;br/&gt;
However, this is not always possible &lt;br/&gt;

???
What happens when you have singular or convergence issues: [link](https://stats.stackexchange.com/questions/110004/how-scared-should-we-be-about-convergence-warnings-in-lme4) &lt;br/&gt; &lt;br/&gt;

Additional information on random effects: [link](https://rpsychologist.com/r-guide-longitudinal-lme-lmer)

---

## Significance testing: fixed effects


```r
#install.packages('lmerTest')
require(lmerTest)
mult2&lt;-lmer(CalorieIntake~Age+(1+Age|Babies_id), data=Babies)
print(summary(mult2), cor=F)
```

```
## Linear mixed model fit by REML. t-tests use Satterthwaite's method [
## lmerModLmerTest]
## Formula: CalorieIntake ~ Age + (1 + Age | Babies_id)
##    Data: Babies
## 
## REML criterion at convergence: 25474.9
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.7037 -0.6672  0.0194  0.6576  4.0965 
## 
## Random effects:
##  Groups    Name        Variance Std.Dev. Corr 
##  Babies_id (Intercept) 35937.8  189.57        
##            Age           701.9   26.49   -0.50
##  Residual              18938.3  137.62        
## Number of obs: 2000, groups:  Babies_id, 10
## 
## Fixed effects:
##             Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)  469.579     60.307   8.995   7.786 2.75e-05 ***
## Age           50.048      8.386   9.001   5.968 0.000211 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

???
REML: [LINK](https://towardsdatascience.com/maximum-likelihood-ml-vs-reml-78cf79bef2cf) &lt;br/&gt;&lt;br/&gt; 

Satterweight approximation of degrees of freedom: [LINK](https://link.springer.com/article/10.3758/s13428-016-0809-y)
---

## Significance testing: random effects 

We are not interested in understanding exactly which levels of random factors are different in comparison to the mean &lt;br/&gt;&lt;br/&gt; 

We are interested in making correct estimates of our coefficients &lt;br/&gt;&lt;br/&gt; 

However, we can compare whether random structure adds more information by comparing the nested models &lt;br/&gt;

---
class: inverse, middle, center
# Practical aspect
---

## Data

Relation between digital-screen use and the mental well-being of adolescents: [LINK](https://journals.sagepub.com/doi/10.1177/0956797616678438)  &lt;br/&gt; &lt;br/&gt;
.pull-left[
Outcome:
- Mental well-being: mwbi  &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;

Predictors:
- TV weekdays: Watchwk_adj  &lt;br/&gt;
- TV weekends: Watchwe_adj  &lt;br/&gt;
- Computer weekdays: Compwk_adj  &lt;br/&gt;
- Computer weekends: Compwe_adj  &lt;br/&gt;
- Smartphones weekday: Smartwk_adj  &lt;br/&gt;
- Smartphones weekends: Smartwe_adj  &lt;br/&gt;
- Total: sum of those
]
.pull-right[
Ethnicity: Ethnicg &lt;br/&gt; 
Region: Region &lt;br/&gt;
Local area: LANAME &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;

Factors:
male &lt;br/&gt;
minority &lt;br/&gt;
deprived &lt;br/&gt;
]

---

## Reading the data in R


```r
#install.packages('foreign')
require(foreign)
mwell&lt;-read.spss('data.sav', to.data.frame = T)
dim(mwell)
```

```
## [1] 120115     74
```

```r
mwell$Total=mwell$Watchwe_adj+mwell$Watchwk_adj+mwell$Comphwe_adj+mwell$Comphwk_adj+mwell$Smartwe_adj+mwell$Smartwk_adj
```

---

## Important aspects: theory

- Why and when would we want to use multilevel models &lt;br/&gt;
- What can we include in our random structure - types of adjustments &lt;br/&gt;
- Multilevel models versus complete and no pooling &lt;br/&gt;
- Understanding how to specify random structure

---

## Important aspects: practice

- Building linear mixed-effect model
- Specifying random intercepts and slopes
- Comparing nested models 
- Interpreting coefficients from linear mixed-effect models

---
## Literature

Chapter 11, 12 and 13 of "Data Analysis Using Regression and Multilevel/Hierarchical Models" by Andrew Gelman and Jennifer Hill &lt;br/&gt; &lt;br/&gt;


---

# Thank you for your attention
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
